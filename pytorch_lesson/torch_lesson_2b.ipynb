{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本章で使うモジュールのインポート\n",
    "from torch import utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root='./data', train=True, download=False, transform=transforms.ToTensor())  # 学習用データセット\n",
    "train_loader = utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)  # ミニバッチごとにデータを纏める(学習時にはshuffle=True)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=False, transform=transforms.ToTensor())  # 検証用データセット\n",
    "test_loader = utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)  # ミニバッチごとにデータを纏める(学習時にはshuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.parameters())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_data_len = 0 \n",
    "       \n",
    "    for batch_imgs, batch_labels in tqdm(train_loader):\n",
    "        # Flatten the batch of images\n",
    "        batch_imgs = batch_imgs.reshape(-1, 28*28*1)\n",
    "        labels = torch.eye(10)[batch_labels]\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        model.optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(batch_imgs)\n",
    "        # Compute the loss\n",
    "        loss = model.criterion(outputs, labels)\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        \n",
    "        _, pred_labels = torch.max(outputs, axis=1)\n",
    "        batch_size = len(batch_labels)\n",
    "        for i in range(batch_size):\n",
    "            total_data_len += 1\n",
    "            if pred_labels[i] == batch_labels[i]:\n",
    "                total_correct += 1\n",
    "        total_loss += loss.item()\n",
    "            \n",
    "        accuracy = total_correct / total_data_len * 100\n",
    "        loss = total_loss / total_data_len\n",
    "    \n",
    "    return accuracy, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:06<00:00, 88.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy=94.61333333333334, loss=0.00015970281180925668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MlpNet()\n",
    "accracy, loss = train(model, train_loader)\n",
    "print(f\"{accracy=}, {loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy=84.34333333333333, loss=0.0003327992434768627\n"
     ]
    }
   ],
   "source": [
    "model2 = MlpNet2()\n",
    "accracy, loss = train(model2, train_loader)\n",
    "print(f\"{accracy=}, {loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    # モデルを評価モードにする\n",
    "    model.eval()\n",
    "    # 正しい予測数、全体のデータ数を数えるカウンターの0初期化\n",
    "    total_data_len = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        outputs = model(batch_imgs.reshape(-1, 28*28*1))  # 順伝播（=予測）\n",
    "         \n",
    "        # ミニバッチごとの集計\n",
    "        _, pred_labels = torch.max(outputs, axis=1)  # outputsから必要な情報(予測したラベル)のみを取り出す。\n",
    "        batch_size = len(pred_labels)  # バッチサイズの確認\n",
    "        for i in range(batch_size):  # データ一つずつループ,ミニバッチの中身出しきるまで\n",
    "            total_data_len += 1  # 全データ数を集計\n",
    "            if pred_labels[i] == batch_labels[i]:\n",
    "                total_correct += 1 # 正解のデータ数を集計\n",
    "\n",
    "    # 1エポック分の集計\n",
    "    acc = 100.0 * total_correct/total_data_len  # 予測精度の算出\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy=96.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accracy = test(model, test_loader)\n",
    "print(f\"{accracy=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
